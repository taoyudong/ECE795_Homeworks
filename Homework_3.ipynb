{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homework_3",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sq8U3BtmhtRx",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# ECE795 Advanced Big Data Analytics Homework 3\n",
        "\n",
        "Set up Pyspark Environment.\n",
        "\n",
        "Tips for Colab:\n",
        "\n",
        "1. You will be disconnected if you are idle for more than 90 minutes and will be mandatorily disconnected after 12 hour connection. \n",
        "\n",
        "2. Once you got disconnected, you need to execute the codes from the beginning to setup the environment again.\n",
        "\n",
        "3. For the purpose of homework, it should be sufficient since each problem should not take more than 5 minutes to generate the results.\n",
        "\n",
        "4. To facilitate the use of Colab, you can use \"MainMenu - Runtime - Run all” to run all the cells in the notebook. So you do not have to click each cell to setup the environment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lh5NCoc8fsSO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://www-us.apache.org/dist/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.4-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.4-bin-hadoop2.7\"\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEb4HTRwiaJx",
        "colab_type": "text"
      },
      "source": [
        "Congrats! Your Colab is ready to run Pyspark.\n",
        "\n",
        "# Read input text file to RDD \n",
        "\n",
        "Download the input data from [here](https://raw.githubusercontent.com/umddm/ECE795_Homeworks/master/clust_B.txt)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAISFqHXf7dt",
        "colab_type": "code",
        "outputId": "d6f0e54d-2bdc-4b35-9ab6-96c185723f4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "!wget https://raw.githubusercontent.com/umddm/ECE795_Homeworks/master/clust_B_part1.txt\n",
        "!wget https://raw.githubusercontent.com/umddm/ECE795_Homeworks/master/clust_B_part2.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-03 21:22:29--  https://raw.githubusercontent.com/umddm/ECE795_Homeworks/master/clust_B_part1.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 17960365 (17M) [text/plain]\n",
            "Saving to: ‘clust_B_part1.txt’\n",
            "\n",
            "clust_B_part1.txt   100%[===================>]  17.13M  27.4MB/s    in 0.6s    \n",
            "\n",
            "2020-02-03 21:22:30 (27.4 MB/s) - ‘clust_B_part1.txt’ saved [17960365/17960365]\n",
            "\n",
            "--2020-02-03 21:22:31--  https://raw.githubusercontent.com/umddm/ECE795_Homeworks/master/clust_B_part2.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 663094 (648K) [text/plain]\n",
            "Saving to: ‘clust_B_part2.txt’\n",
            "\n",
            "clust_B_part2.txt   100%[===================>] 647.55K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-02-03 21:22:31 (6.49 MB/s) - ‘clust_B_part2.txt’ saved [663094/663094]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21D9EANUvnwF",
        "colab_type": "text"
      },
      "source": [
        "Now that we have input data, we can start to do the homework. \n",
        "\n",
        "In homework 3, we have two input datas, which called 'clust_B_part1.txt' and 'clust_B_part2.txt'. The 'clust_B_part1.txt' contains the data with word id start with 2 to 9, and the 'clust_B_part2.txt' contains the data with count higher than 100.\n",
        "\n",
        "## Question 1: Please generate a pair RDD with all the words appear in clust_B_part1.txt as value and the length of the words as key.\n",
        "\n",
        "### Expected output:\n",
        "```\n",
        "[(1, 'i'),\n",
        " (4, 'love'),\n",
        " (1, 'i'),\n",
        " (2, 'so'),\n",
        " (4, 'hate')]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZeJ7WQCgM8g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#sc.textFile\n",
        "from pyspark import SparkConf, SparkContext\n",
        "sc = SparkContext.getOrCreate()\n",
        "\n",
        "#Question_1:\n",
        "\n",
        "#Fill out here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3vYyp5dwOm_",
        "colab_type": "text"
      },
      "source": [
        "## Question 2: Please generate a RDD contains the words, which has the same length and occurrence, in clust_B_part1.txt \n",
        "### Sample:\n",
        "```\n",
        "Input RDD = ['word', 'where', 'word', 'word', 'word', 'like', 'am', 'am', 'i']\n",
        "\n",
        "words       length       occurrences\n",
        "word        4            4\n",
        "where       5            1\n",
        "like        4            1\n",
        "am          2            2\n",
        "i           1            1\n",
        "\n",
        "Output RDD = ['word', 'am', 'i']\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eja1BLiaTThT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Question_2\n",
        "\n",
        "#Fill out here\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FHVHVQjd4P1",
        "colab_type": "text"
      },
      "source": [
        "## Question 3: Please output the top 10 words that appear most in both 'clust_B_part1.txt' and 'clust_B_part2.txt', and the number of occurrences for these 10 words.\n",
        "\n",
        "### Expected output:\n",
        "```\n",
        "'clust_B_part1.txt'\n",
        "('i', 1000)\n",
        "('the', 999)\n",
        "('most', 888)\n",
        "...\n",
        "\n",
        "'clust_B_part2.txt'\n",
        "('word', 1000)\n",
        "('appear', 999)\n",
        "('times', 888)\n",
        "...\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJsxix2Xd3-Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Question_3\n",
        "\n",
        "#Fill out here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIy1IL965Ogm",
        "colab_type": "text"
      },
      "source": [
        "## Question 4: Please count how many words have one occurrence in 'clust_B_part1.txt', 'clust_B_part2.txt', and the combined RDD of them. \n",
        "\n",
        "### Expected output:\n",
        "```\n",
        "words have one occurrence in 'clust_B_part1.txt': 1000\n",
        "\n",
        "words have one occurrence in 'clust_B_part2.txt': 100\n",
        "\n",
        "words have one occurrence in combine RDD: 999\n",
        "...\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OmbLiCQ5ctu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Question_4\n",
        "\n",
        "#Fill out here"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}